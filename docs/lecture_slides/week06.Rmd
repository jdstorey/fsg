---
title: QCB 508 -- Week 6
author: John D. Storey
date: Spring 2020
output: 
  revealjs::revealjs_presentation:
    theme: simple
    transition: slide
    center: true
    highlight: null
    self_contained: false
    lib_dir: libs
    reveal_plugins: ["chalkboard", "zoom"]
    reveal_options:
      slideNumber: false
      progress: true
    includes:
      before_body: customization/doc_prefix.html
---

\providecommand{\E}{\operatorname{E}}
\providecommand{\V}{\operatorname{Var}}
\providecommand{\Cov}{\operatorname{Cov}}
\providecommand{\se}{\operatorname{se}}
\providecommand{\logit}{\operatorname{logit}}
\providecommand{\iid}{\; \stackrel{\text{iid}}{\sim}\;}
\providecommand{\asim}{\; \stackrel{.}{\sim}\;}
\providecommand{\xs}{x_1, x_2, \ldots, x_n}
\providecommand{\Xs}{X_1, X_2, \ldots, X_n}
\providecommand{\bB}{\boldsymbol{B}}
\providecommand{\bb}{\boldsymbol{\beta}}
\providecommand{\bx}{\boldsymbol{x}}
\providecommand{\bX}{\boldsymbol{X}}
\providecommand{\by}{\boldsymbol{y}}
\providecommand{\bY}{\boldsymbol{Y}}
\providecommand{\bz}{\boldsymbol{z}}
\providecommand{\bZ}{\boldsymbol{Z}}
\providecommand{\be}{\boldsymbol{e}}
\providecommand{\bE}{\boldsymbol{E}}
\providecommand{\bs}{\boldsymbol{s}}
\providecommand{\bS}{\boldsymbol{S}}
\providecommand{\bP}{\boldsymbol{P}}
\providecommand{\bI}{\boldsymbol{I}}
\providecommand{\bD}{\boldsymbol{D}}
\providecommand{\bd}{\boldsymbol{d}}
\providecommand{\bW}{\boldsymbol{W}}
\providecommand{\bw}{\boldsymbol{w}}
\providecommand{\bM}{\boldsymbol{M}}
\providecommand{\bPhi}{\boldsymbol{\Phi}}
\providecommand{\bphi}{\boldsymbol{\phi}}
\providecommand{\bN}{\boldsymbol{N}}
\providecommand{\bR}{\boldsymbol{R}}
\providecommand{\bu}{\boldsymbol{u}}
\providecommand{\bU}{\boldsymbol{U}}
\providecommand{\bv}{\boldsymbol{v}}
\providecommand{\bV}{\boldsymbol{V}}
\providecommand{\bO}{\boldsymbol{0}}
\providecommand{\bOmega}{\boldsymbol{\Omega}}
\providecommand{\bLambda}{\boldsymbol{\Lambda}}
\providecommand{\bSig}{\boldsymbol{\Sigma}}
\providecommand{\bSigma}{\boldsymbol{\Sigma}}
\providecommand{\bt}{\boldsymbol{\theta}}
\providecommand{\bT}{\boldsymbol{\Theta}}
\providecommand{\bpi}{\boldsymbol{\pi}}
\providecommand{\argmax}{\text{argmax}}
\providecommand{\KL}{\text{KL}}
\providecommand{\fdr}{{\rm FDR}}
\providecommand{\pfdr}{{\rm pFDR}}
\providecommand{\mfdr}{{\rm mFDR}}
\providecommand{\bh}{\hat}
\providecommand{\dd}{\lambda}
\providecommand{\q}{\operatorname{q}}

```{r, message=FALSE, echo=FALSE, cache=FALSE}
source("./customization/knitr_options.R")
```

# <img src="./images/howto.jpg"></img>

# Bayesian Estimation

## Assumptions 

We will assume that $(X_1, X_2, \ldots, X_n) | \theta \iid F_{\theta}$ with prior distribution $\theta \sim F_{\tau}$ unless stated otherwise. Shorthand for the former is $\boldsymbol{X} | \theta \iid F_{\theta}$.

We will write the pdf or pmf of $X$ as $f(x | \theta)$ as opposed to $f(x ; \theta)$ because in the Bayesian framework this actually represents conditional probability. 

We will write the pdf or pmf of $\theta$ as $f(\theta)$ or $f(\theta ; \tau)$ or $f(\theta | \tau)$.  Always remember that prior distributions require paramater values, even if we don't explicitly write them.

## Posterior Distribution

The posterior distribution of $\theta | \boldsymbol{X}$ is obtained through Bayes theorem:

\begin{align*}
f(\theta | \boldsymbol{x}) & = \frac{f(\boldsymbol{x} | \theta) f(\theta)}{f(\boldsymbol{x})} = \frac{f(\boldsymbol{x} | \theta) f(\theta)}{\int f(\boldsymbol{x} | \theta^*) f(\theta^*) d\theta^*} \\
& \propto L(\theta ; \boldsymbol{x}) f(\theta)
\end{align*}

## Posterior Expectation

A very common point estimate of $\theta$ in Bayesian inference is the posterior expected value:

\begin{align*}
\operatorname{E}[\theta | \boldsymbol{x}]  & = \int \theta f(\theta | \boldsymbol{x}) d\theta \\
 & = \frac{\int \theta L(\theta ; \boldsymbol{x}) f(\theta) d\theta}{\int L(\theta ; \boldsymbol{x}) f(\theta) d\theta}
\end{align*}

## Posterior Interval

The Bayesian analog of the frequentist confidence interval is the $1-\alpha$ posterior interval, where $C_{\ell}$ and $C_{u}$ are determined so that:

$$
1-\alpha = \Pr(C_\ell \leq \theta \leq C_u | \boldsymbol{x})
$$

## Maximum *A Posteriori* Probability

The maximum *a posteriori* probability (MAP) is the value (or values) of $\theta$ that maximize the posterior pdf or pmf:

\begin{align*}
\hat{\theta}_{\text{MAP}} & = \operatorname{argmax}_\theta \Pr(\theta | \boldsymbol{x}) \\
 & = \operatorname{argmax}_\theta L(\theta ; \boldsymbol{x}) f(\theta)
\end{align*}

This is a frequentist-esque use of the Bayesian framework.

## Loss Functions

Let $\mathcal{L}\left(\theta, \tilde{\theta}\right)$ be a **loss function** for a given estimator $\tilde{\theta}$.  Examples are

$$
\mathcal{L}\left(\theta, \tilde{\theta}\right) = \left(\theta - \tilde{\theta}\right)^2 \mbox{ or } 
\mathcal{L}\left(\theta, \tilde{\theta}\right) = \left|\theta - \tilde{\theta}\right|.
$$

Note that, where the expected value is over $f(\boldsymbol{x}; \theta)$: 

\begin{align*}
\operatorname{E}\left[\left(\theta - \tilde{\theta}\right)^2\right] & = \left(\operatorname{E}\left[\tilde{\theta}\right] - \theta\right)^2 + \operatorname{Var}\left(\tilde{\theta}\right) \\
 & = \mbox{bias}^2 + \mbox{variance}
\end{align*}

## Bayes Risk

The **Bayes risk**, $R\left(\theta, \tilde{\theta}\right)$, is the expected loss with respect to the posterior:

$$
\E\left[ \left. \mathcal{L}\left(\theta, \tilde{\theta}\right) \right| \boldsymbol{x} \right]
= \int \mathcal{L}\left(\theta, \tilde{\theta}\right) f(\theta | \boldsymbol{x}) d\theta
$$

## Bayes Estimators

The **Bayes estimator** minimizes the Bayes risk.

The posterior expectation $\E\left[ \left. \theta \right| \boldsymbol{x} \right]$ minimizes the Bayes risk of $\mathcal{L}\left(\theta, \tilde{\theta}\right) = \left(\theta - \tilde{\theta}\right)^2$.

The median of $f(\theta | \boldsymbol{x})$, calculated by $F^{-1}_{\theta | \boldsymbol{x}}(1/2)$, minimizes the Bayes risk of $\mathcal{L}\left(\theta, \tilde{\theta}\right) = \left|\theta - \tilde{\theta}\right|$.


# Bayesian Classification

## Assumptions

Let $(X_1, X_2, \ldots, X_n) | \theta \iid F_\theta$ where $\theta \in \Theta$ and $\theta \sim F_{\tau}$.  Let $\Theta_0, \Theta_1 \subseteq \Theta$ so that $\Theta_0 \cap \Theta_1 = \varnothing$ and $\Theta_0 \cup \Theta_1 = \Theta$.

Given observed data $\boldsymbol{x}$, we wish to classify whether $\theta \in \Theta_0$ or $\theta \in \Theta_1$.  

This is the Bayesian analog of hypothesis testing.

## Prior Probability on *H*

Let $H$ be a rv such that $H=0$ when $\theta \in \Theta_0$ and $H=1$ when $\theta \in \Theta_1$.

From the prior distribution on $\theta$, we can calculate 

$$
\Pr(H=0) = \int_{\theta \in \Theta_0} f(\theta) d\theta
$$ 

and $\Pr(H=1) = 1-\Pr(H=0)$.  

## Posterior Probability

Using Bayes theorem, we can also calculate

\begin{align*}
\Pr(H=0 | \boldsymbol{x}) 
& = \frac{f(\boldsymbol{x} | H=0) \Pr(H=0)}{f(\boldsymbol{x})} \\
& = \frac{\int_{\theta \in \Theta_0} f(\boldsymbol{x} | \theta) f(\theta) d\theta}{\int_{\theta \in \Theta} f(\boldsymbol{x} | \theta) f(\theta) d\theta}
\end{align*}

where note that $\Pr(H=1 | \boldsymbol{x}) = 1-\Pr(H=0 | \boldsymbol{x})$.

## Loss Function

Let $\mathcal{L}\left(\tilde{H}, H\right)$ be such that 

\begin{align*}
\mathcal{L}\left(\tilde{H}=1, H=0 \right) & = c_{I}\\
\mathcal{L}\left(\tilde{H}=0, H=1 \right) & = c_{II}
\end{align*}

for some $c_{I}, c_{II} > 0$.

## Bayes Risk

The Bayes risk, $R\left(\tilde{H}, H\right)$, is 

\begin{align*}
\operatorname{E}\left[ \left. \mathcal{L}\left(\theta, \tilde{\theta}\right) \right| \boldsymbol{x} \right]
& = c_{I} \Pr(\tilde{H}=1, H=0) + c_{II} \Pr(\tilde{H}=0, H=1) \\
& = c_{I} \Pr(\tilde{H}=1 | H=0) \Pr(H=0) \\
& \quad\quad + c_{II} \Pr(\tilde{H}=0 | H=1) \Pr(H=1)
\end{align*}

Notice how this balances what frequentists call Type I error and Type II error.

## Bayes Rule

The estimate $\tilde{H}$ that minimizes $R\left(\tilde{H}, H\right)$ is

$$\tilde{H}=1 \mbox{ when } \Pr(H=1 | \boldsymbol{x}) \geq \frac{c_{I}}{c_{I} + c_{II}}$$

and $\tilde{H}=0$ otherwise.

# Priors

## Conjugate Priors

A **conjugate prior** is a prior distribution for a data generating distribution so that the posterior distribution is of the same type as the prior.

Conjugate priors are useful for obtaining stratightforward calculations of the posterior.

There is a systematic method for calculating conjugate priors for exponential family distributions.

## Example: Beta-Bernoulli

Suppose $\boldsymbol{X} | \mu \iid \mbox{Bernoulli}(p)$ and suppose that $p \sim \mbox{Beta}(\alpha, \beta)$.

\begin{align*}
f(p | \boldsymbol{x}) & \propto L(p ; \boldsymbol{x}) f(p) \\
 & = p^{\sum x_i} (1-p)^{\sum (1-x_i)} p^{\alpha - 1} (1-p)^{\beta-1} \\
 & = p^{\alpha - 1 + \sum x_i} (1-p)^{\beta - 1 + \sum (1-x_i)} \\
 & \propto \mbox{Beta}(\alpha + \sum x_i, \beta + \sum (1-x_i))
\end{align*}

Therefore,
$$
\E[p | \boldsymbol{x}] = \frac{\alpha + \sum x_i}{\alpha + \beta + n}.
$$

## Example: Normal-Normal

Suppose $\boldsymbol{X} | \mu \iid \mbox{Normal}(\mu, \sigma^2)$, where $\sigma^2$ is known, and suppose that $\mu \sim \mbox{Normal}(a, b^2)$. 

Then it can be shown that $\mu | \boldsymbol{x} \sim \mbox{Normal}(\E[\mu | \boldsymbol{x}], \V(\mu | \boldsymbol{x}))$ where

$$
\E[\mu | \boldsymbol{x}] = \frac{b^2}{\frac{\sigma^2}{n} + b^2} \overline{x} + \frac{\frac{\sigma^2}{n}}{\frac{\sigma^2}{n} + b^2} a
$$

$$
\V(\mu | \boldsymbol{x}) = \frac{b^2 \frac{\sigma^2}{n}}{\frac{\sigma^2}{n} + b^2}
$$

## Jeffreys Prior

If we do inference based on prior $\theta \sim F_{\tau}$ to obtain $f(\theta | \boldsymbol{x}) \propto L(\theta; \boldsymbol{x}) f(\theta)$, it follows that this inference may *not* be invariant to transformations of $\theta$, such as $\eta = g(\theta)$.  

If we utilize a **Jeffreys prior**, which means it is such that

$$f(\theta) \propto \sqrt{I(\theta)}$$

then the prior will be invariant to transformations of $\theta$.  We would want to show that $f(\theta) \propto \sqrt{I(\theta)}$ implies $f(\eta) \propto \sqrt{I(\eta)}$.

## Examples: Jeffreys Priors

\  

Normal$(\mu, \sigma^2)$, $\sigma^2$ known: $f(\mu) \propto 1$

Normal$(\mu, \sigma^2)$, $\mu$ known: $f(\sigma) \propto \frac{1}{\sigma}$

Poisson$(\lambda)$: $f(\lambda) \propto \frac{1}{\sqrt{\lambda}}$

Bernoulli$(p)$: $f(p) \propto \frac{1}{\sqrt{p(1-p)}}$

## Improper Prior

An **improper prior** is a prior such that $\int f(\theta) d\theta = \infty$.  Nevertheless, sometimes it still may be the case that $f(\theta | \boldsymbol{x}) \propto L(\theta; \boldsymbol{x}) f(\theta)$ yields a probability distribution.

Take for example the case where $\boldsymbol{X} | \mu \iid \mbox{Normal}(\mu, \sigma^2)$, where $\sigma^2$ is known, and suppose that $f(\mu) \propto 1$.  Then $\int f(\theta) d\theta = \infty$, but

$$ f(\theta | \boldsymbol{x}) \propto L(\theta; \boldsymbol{x}) f(\theta) \sim \mbox{Normal}\left(\overline{x}, \sigma^2/n\right)$$

which is a proper probability distribution.

# Empirical Bayes

## Rationale

Under the scenario that $\boldsymbol{X} | \theta \iid F_{\theta}$ with prior distribution $\theta \sim F_{\tau}$, we have to determine values for $\tau$.  

The **empirical Bayes** approach uses the observed data to estimate the prior parameter(s), $\tau$.

This is especially useful for high-dimensional data when many parameters are simultaneously drawn from a prior with multiple observations drawn per parameter realization.

## Approach

The usual approach is to first integrate out the parameter to obtain

$$
f(\boldsymbol{x} ; \tau) = \int f(\boldsymbol{x} | \theta) f(\theta ; \tau) d\theta.
$$

An estimation method (such as MLE) is then applied to estimate $\tau$. Then inference proceeds as usual under the assumption that $\theta \sim f(\theta ; \hat{\tau})$.

## Example: Normal

Suppose that $X_i | \mu_i \sim \mbox{Normal}(\mu_i, 1)$ for $i=1, 2, \ldots, n$ where these rv's are independent.  Also suppose that $\mu_i \iid \mbox{Normal}(a, b^2)$. 

$$
f(x_i ; a, b) = \int f(x_i | \mu_i) f(\mu_i; a, b) d\mu_i \sim \mbox{Normal}(a, 1+b^2).
$$

$$
\implies \hat{a} = \overline{x}, \ 1+\hat{b}^2 =  \frac{\sum_{k=1}^n (x_k - \overline{x})^2}{n}
$$


----

\begin{align*}
\operatorname{E}[\mu_i | x_i] & = \frac{1}{1+b^2}a + \frac{b^2}{1+b^2}x_i \implies \\
 & \\
\hat{\operatorname{E}}[\mu_i | x_i] & = \frac{1}{1+\hat{b}^2}\hat{a} + \frac{\hat{b}^2}{1+\hat{b}^2}x_i \\
 & = \frac{n}{\sum_{k=1}^n (x_k - \overline{x})^2} \overline{x} + \left(1-\frac{n}{\sum_{k=1}^n (x_k - \overline{x})^2}\right) x_i
\end{align*}



# Numerical Methods for Likelihood

## Challenges

Frequentist model:

$$X_1, X_2, \ldots, X_n \iid F_{\bt}$$

Bayesian model:

$$X_1, X_2, \ldots, X_n | \bt \iid F_{\bt} \mbox{ and } \bt \sim F_{\boldsymbol{\tau}}$$

Sometimes it's not possible to find formulas for $\hat{\bt}_{\text{MLE}}$, $\hat{\bt}_{\text{MAP}}$, $\E[\bt | \bx]$, or $f(\bt | \bx)$.  We have to use numerical methods instead.

## Approaches

Frequently used *numerical* approaches to likelihood based inference:

- Expectation-maximization (EM) algorithm
- Variational inference
- Markov chain Monte Carlo (MCMC)
    - Metropolis sampling
    - Metropolis-Hastings sampling
    - Gibbs sampling

# Latent Variable Models

## Definition

Latent variables (or hidden variables) are random variables that are present in the model, but unobserved.

We will denote latent variables by $Z$, and we will assume $$(X_1, Z_1), (X_2, Z_2), \ldots, (X_n, Z_n) \iid F_{\bt}.$$ A realized value of $Z$ is $z$, $\bZ = (Z_1, Z_2, \ldots, Z_n)^T$, etc.

The EM algorithm and variational inference involve latent variables. 

Bayesian models are a special case of latent variable models: the unobserved random parameters are latent variables.

## Empirical Bayes Revisited

In the earlier EB example, we supposed that $X_i | \mu_i \sim \mbox{Normal}(\mu_i, 1)$ for $i=1, 2, \ldots, n$ where these rv's are independent, and also that $\mu_i \iid \mbox{Normal}(a, b^2)$.

The unobserved parameters $\mu_1, \mu_2, \ldots, \mu_n$ are latent variables.  In this case, $\bt = (a, b^2)$.

## Normal Mixture Model

Suppose $\Xs \iid F_{\bt}$ where $\bt = (\pi_1, \ldots, \pi_K, \mu_1, \ldots, \mu_K, \sigma^2_1, \ldots, \sigma^2_K)$ with pdf

$$
f(\bx ; \bt) = \prod_{i=1}^n \sum_{k=1}^K \pi_k \frac{1}{\sqrt{2\pi\sigma^2_k}} \exp \left\{ -\frac{(x_i - \mu_k)^2}{2 \sigma^2_k} \right\}.
$$

The MLEs of the unknown paramaters cannot be found analytically.  This is a mixture common model to work with in applications, so we need to be able to estimate the parameters.

----

There is a latent variable model that produces the same maerginal distribution and likelihood function.  Let $\bZ_1, \bZ_2, \ldots, \bZ_n \iid \mbox{Multinomial}_K(1, \bpi)$ where $\bpi = (\pi_1, \ldots, \pi_K)$. Note that $Z_{ik} \in \{0, 1\}$ and $\sum_{k=1}^K Z_{ik} = 1$. Let $[X_i | Z_{ik} = 1] \sim \mbox{Normal}(\mu_k, \sigma^2_k)$, where $\{X_i | \bZ_i\}_{i=1}^{n}$ are jointly independent.

The joint pdf is

$$
f(\bx, \bz; \bt) = \prod_{i=1}^n \prod_{k=1}^K  \left[ \pi_k \frac{1}{\sqrt{2\pi\sigma^2_k}} \exp \left\{ -\frac{(x_i - \mu_k)^2}{2 \sigma^2_k} \right\} \right]^{z_{ik}}.
$$

----

Note that 

$$
f(\bx, \bz; \bt) = \prod_{i=1}^n f(x_i, \bz_i; \bt).
$$
It can be verified that $f(\bx ; \bt)$ is the marginal distribution of this latent variable model:

$$
f(x_i ; \bt) = \sum_{\bz_i} f(x_i, \bz_i; \bt) = \sum_{k=1}^K \pi_k \frac{1}{\sqrt{2\pi\sigma^2_k}} \exp \left\{ -\frac{(x_i - \mu_k)^2}{2 \sigma^2_k} \right\}.
$$

## Bernoulli Mixture Model

Suppose $\Xs \iid F_{\bt}$ where $\bt = (\pi_1, \ldots, \pi_K, p_1, \ldots, p_K)$ with pdf

$$
f(\bx ; \bt) = \prod_{i=1}^n \sum_{k=1}^K \pi_k p_k^{x_i} (1-p_k)^{1-x_i}.
$$

As in the Normal mixture model, the MLEs of the unknown paramaters cannot be found analytically.

----

As before, there is a latent variable model that produces the same maerginal distribution and likelihood function.  Let $\bZ_1, \bZ_2, \ldots, \bZ_n \iid \mbox{Multinomial}_K(1, \bpi)$ where $\bpi = (\pi_1, \ldots, \pi_K)$. Note that $Z_{ik} \in \{0, 1\}$ and $\sum_{k=1}^K Z_{ik} = 1$. Let $[X_i | Z_{ik} = 1] \sim \mbox{Bernoulli}(p_k)$, where $\{X_i | \bZ_i\}_{i=1}^{n}$ are jointly independent.

The joint pdf is

$$
f(\bx, \bz; \bt) = \prod_{i=1}^n \prod_{k=1}^K  \left[ p_k^{x_i} (1-p_k)^{1-x_i} \right]^{z_{ik}}.
$$

# EM Algorithm

## Rationale

For any likelihood function, $L(\bt ; \bx) = f(\bx; \bt)$, there is an abundance of optimization methods that can be used to find the MLE or MAP. However:

- Optimization methods can be messy to implement
- There may be probabilistic structure that we can use to simplify the optimization process and also provide theoretical guarantees on its convergence
- Optimization isn't necessarily the only goal, but one may also be interested in point estimates of the latent variable values


## Requirement

The expectation-maximization (EM) algorithm allows us to calculate MLEs and MAPs when certain geometric properties are satisfied in the probabilistic model.

In order for the EM algorithm to be a practical approach, then we should have a latent variable model $f(\bx, \bz; \bt)$ that is used to do inference on $f(\bx; \bt)$ or $f(\bt | \bx)$.  

Note: Sometimes $(\bx, \bz)$ is called the **complete data** and $\bx$ is called the **observed data** when we are using the EM as a method for dealing with missing data.

## The Algorithm

1. Choose initial value $\bt^{(0)}$

2. Calculate $f(\bz | \bx, \bt^{(t)})$

3. Calculate
$$Q(\bt, \bt^{(t)}) = \E_{\bZ|\bX=\bx}\left[\log f(\bx, \bZ; \bt); \bt^{(t)}\right]$$

4. Set 
$$\bt^{(t+1)} = \argmax_{\bt} Q(\bt, \bt^{(t)})$$

5. Iterate until convergence and set $\widehat{\bt} = \bt^{(\infty)}$

## $Q(\bt, \bt^{(t)})$

Continuous $\bZ$:

$$Q(\bt, \bt^{(t)}) = \int \log f(\bx, \bz; \bt) f(\bz | \bx ; \bt^{(t)}) d\bz$$

Discrete $\bZ$:

$$Q(\bt, \bt^{(t)}) = \sum_{\bz} \log f(\bx, \bz; \bt) f(\bz | \bx ; \bt^{(t)})$$

## EM for MAP

If we wish to calculate the MAP we replace $Q(\bt, \bt^{(t)})$ with

$$Q(\bt, \bt^{(t)}) = \E_{\bZ|\bX=\bx}\left[\log f(\bx, \bZ; \bt); \bt^{(t)}\right] + \log f(\bt)$$

where $f(\bt)$ is the prior distribution on $\bt$. 

# EM Examples

## Normal Mixture Model

Returning to the Normal mixture model [introduced earlier](#/normal-mixture-model), we first calculate

$$
\log f(\bx, \bz; \bt) = \sum_{i=1}^n \sum_{k=1}^K z_{ik} \log \pi_k + z_{ik} \log \phi(x_i; \mu_k, \sigma^2_k)
$$

where 

$$
\phi(x_i; \mu_k, \sigma^2_k) = \frac{1}{\sqrt{2\pi\sigma^2_k}} \exp \left\{ -\frac{(x_i - \mu_k)^2}{2 \sigma^2_k} \right\}.
$$

----

In caculating 

$$Q(\bt, \bt^{(t)}) = \E_{\bZ|\bX=\bx}\left[\log f(\bx, \bZ; \bt); \bt^{(t)}\right]$$

we only need to know $\E_{\bZ|\bX=\bx}[Z_{ik} | \bx; \bt]$, which turns out to be

$$
\E_{\bZ|\bX=\bx}[Z_{ik} | \bx; \bt] = \frac{\pi_k \phi(x_i; \mu_k, \sigma^2_k)}{\sum_{j=1}^K \pi_j \phi(x_i; \mu_j, \sigma^2_j)}.
$$

----

Note that we take 

$$Q(\bt, \bt^{(t)}) = \E_{\bZ|\bX=\bx}\left[\log f(\bx, \bZ; \bt); \bt^{(t)}\right]$$

so the parameter in $\log f(\bx, \bZ; \bt)$ is a free $\bt$, but the paramaters used to take the conditional expectation of $\bZ$ are fixed at $\bt^{(t)}$.  Let's define

$$
\hat{z}_{ik}^{(t)} = \E\left[z_{ik} | \bx; \bt^{(t)}\right] = \frac{\pi^{(t)}_k \phi(x_i; \mu^{(t)}_k, \sigma^{2, (t)}_k)}{\sum_{j=1}^K \pi^{(t)}_j \phi(x_i; \mu^{(t)}_j, \sigma^{2, (t)}_j)}.
$$

## E-Step

We calculate 

$$Q(\bt, \bt^{(t)}) = \E_{\bZ|\bX=\bx}\left[\log f(\bx, \bZ; \bt); \bt^{(t)}\right]$$
$$ = \sum_{i=1}^n \sum_{k=1}^K \hat{z}_{ik}^{(t)} \log \pi_k + \hat{z}_{ik}^{(t)} \log \phi(x_i; \mu_k, \sigma^2_k)$$

At this point the parameters making up $\hat{z}_{ik}^{(t)}$ are fixed at $\bt^{(t)}$.

## M-Step

We now caculate $\bt^{(t+1)} = \argmax_{\bt} Q(\bt, \bt^{(t)}$, which yields:

$$
\pi_k^{(t+1)} = \frac{\sum_{i=1}^n \hat{z}_{ik}^{(t)}}{n}
$$

$$
\mu_k^{(t+1)} = \frac{\sum_{i=1}^n \hat{z}_{ik}^{(t)} x_i}{\sum_{i=1}^n \hat{z}_{ik}^{(t)}}
$$

$$
\sigma_k^{2, (t+1)}  = \frac{\sum_{i=1}^n \hat{z}_{ik}^{(t)} \left(x_i - \mu_k^{(t+1)} \right)^2}{\sum_{i=1}^n \hat{z}_{ik}^{(t)}}
$$

<p style="font-size: 0.5em;">
Note:  You need to use a [Lagrange multiplier](http://math.stackexchange.com/questions/421105/maximum-likelihood-estimator-of-parameters-of-multinomial-distribution) to obtain $\{\pi_k^{(t+1)}\}_{k=1}^{K}$.
</p>


## Caveat

If we assign one and only one data point to mixture component $k$, meaning $\mu_k^{(t)} = x_i$ and $\hat{z}_{ik}^{(t)}=1$ for some $k$ and $i$, then as $\sigma^{2, (t)}_k \rightarrow 0$, the likelihood goes to $\infty$.  

Therefore, when implementing the EM algorithm for this particular Normal mixture model, we have to be careful to bound all $\sigma^{2, (t)}_k$ away from zero and avoid this scenario.

## Yeast Gene Expression

<p style="font-size: 0.75em;">
Measured ratios of the nuclear to cytoplasmic fluorescence for a protein-GFP construct that is hypothesized as being nuclear in mitotic cells and largely cytoplasmic in mating cells.
</p>

```{r, echo=FALSE}
df = read.table("./data/gfp.txt")
names(df) <- c("gfp", "truth")
df$truth <- as.character(df$truth)
df$truth[df$truth=="1"] <- "mating"
df$truth[df$truth=="2"] <- "mitotic"
df$truth <- as.factor(df$truth)
x <- df$gfp
tmu1 <- mean(x[1:60])
ts1 <- var(x[1:60])
tmu2 <- mean(x[61:120])
ts2 <- var(x[61:120])
ft <- rep(0, 120)
ft[1:60] <- dnorm(x[1:60], mean=tmu1, sd=sqrt(ts1))
ft[61:120] <- dnorm(x[61:120], mean=tmu2, sd=sqrt(ts2))

df <- data.frame(df, ft=ft)

ggplot(df) +
  geom_histogram(mapping = aes(x=gfp, y=..density.., fill=truth), 
                 binwidth=0.9, color="black", alpha=0.6, position="identity") +
  scale_fill_manual(values=c("red", "blue")) +
  geom_line(aes(x=gfp, y=ft, color=truth), size=1.5) + 
  scale_color_manual(values=c("grey", "grey")) 
```

## Initialize Values

```{r}
set.seed(508)
B <- 100
p <- rep(0,B)
mu1 <- rep(0,B)
mu2 <- rep(0,B)
s1 <- rep(0,B)
s2 <- rep(0,B)
p[1] <- runif(1, min=0.1, max=0.9)
mu.start <- sample(x, size=2, replace=FALSE)
mu1[1] <- min(mu.start)
mu2[1] <- max(mu.start)
s1[1] <- var(sort(x)[1:60])
s2[1] <- var(sort(x)[61:120])
z <- rep(0,120)
```

## Run EM Algorithm

```{r}
for(i in 2:B) {
  z <- (p[i-1]*dnorm(x, mean=mu2[i-1], sd=sqrt(s2[i-1])))/
    (p[i-1]*dnorm(x, mean=mu2[i-1], sd=sqrt(s2[i-1])) + 
       (1-p[i-1])*dnorm(x, mean=mu1[i-1], sd=sqrt(s1[i-1])))
  mu1[i] <- sum((1-z)*x)/sum(1-z)
  mu2[i] <- sum(z*x)/sum(z)
  s1[i] <- sum((1-z)*(x-mu1[i])^2)/sum(1-z)
  s2[i] <- sum(z*(x-mu2[i])^2)/sum(z)
  p[i] <- sum(z)/length(z)
}

tail(cbind(mu1, s1, mu2, s2, p), n=3)
```

## Fitted Mixture Distribution

```{r, echo=FALSE}
fe <- rep(0, 120)
fe <- (1-z)*dnorm(x, mean=mu1[B], sd=sqrt(s1[B])) + 
  z*dnorm(x, mean=mu2[B], sd=sqrt(s2[B]))
df <- data.frame(df, fe=fe)

ggplot(df) +
  geom_histogram(mapping = aes(x=gfp, y=..density.., fill=truth), 
                 binwidth=0.9, color="black", alpha=0.6, position="identity") +
  scale_fill_manual(values=c("red", "blue")) +
  geom_line(aes(x=gfp, y=ft, color=truth), size=1.5) + 
  scale_color_manual(values=c("grey", "grey")) +
  geom_line(aes(x=gfp, y=fe), size=1.5)
#  geom_line(aes(x=gfp, y=fe, color=truth), size=1.5) + 
#  scale_color_manual(values=c("black", "black")) +
#  geom_line(aes(x=gfp[1:60], y=ft[1:60]), size=1.5)
```

## Bernoulli Mixture Model

As an exercise, derive the EM algorithm of the Bernoilli mixture model [introduced earlier](#/bernoulli-mixture-model).

Hint: Replace $\phi(x_i; \mu_k, \sigma^2_k)$ with the appropriate Bernoilli pmf.

## Other Applications of EM

- Dealing with missing data
- Multiple imputation of missing data
- Truncated observations
- Bayesian hyperparameter estimation
- Hidden Markov models

## EM Increases Likelihood

Since $\bt^{(t+1)} = \argmax_{\bt} Q(\bt, \bt^{(t)})$, it follows that 

$$Q(\bt^{(t+1)}, \bt^{(t)}) \geq Q(\bt^{(t)}, \bt^{(t)}).$$  

Chapter 43 of *Foundations of Applied Statistics* details additional mathematics that shows:

$$
\log f(\bx ; \bt^{(t+1)}) \geq \log f(\bx; \bt^{(t)}).
$$

# Markov Chain Monte Carlo

## Motivation

When performing Bayesian inferece, it is often (but not always) possible to calculate 

$$f(\bt | \bx) \propto L(\bt; \bx) f(\bt)$$

but it is typically much more difficult to calculate

$$f(\bt | \bx) = \frac{L(\bt; \bx) f(\bt)}{f(\bx)}.$$

Markov chain Monte Carlo is a method for simulating data approximately from $f(\bt | \bx)$ with knowledge of only $L(\bt; \bx) f(\bt)$.

## Note

MCMC can be used to approximately simulate data from any distribution that is only proportionally characterized, but it is probably most well know for doing so in the context of Bayesian infererence.

We will explain MCMC in the context of Bayesian inference.

## Big Picture

We draw a Markov chain of $\bt$ values so that, in some asymptotic sense, these are equivalent to iid draws from $f(\bt | \bx)$.

The draws are done competitively so that the next draw of a realization of $\bt$ depends on the current value.  

The Markov chain is set up so that it only depends on $L(\bt; \bx) f(\bt)$.

*A lot* of practical decisions need to be made by the user, so utilize MCMC carefully.

## Metropolis-Hastings Algorithm

1. Initialize $\bt^{(0)}$

2. Generate $\bt^{*} \sim q(\bt | \bt^{(b)})$ for some pdf or pmf $q(\cdot | \cdot)$

3. With probablity 
$$A(\bt^{*}, \bt^{(b)}) = \min\left( 1, \frac{L(\bt^{*}; \bx) f(\bt^{*}) q(\bt^{(b)} | \bt^{*})}{L(\bt^{(b)}; \bx) f(\bt^{(b)}) q(\bt^{*} | \bt^{(b)})} \right)$$
set $\bt^{(b+1)} = \bt^{*}$.  Otherise, set $\bt^{(b+1)} = \bt^{(b)}$

4. Continue for $b = 1, 2, \ldots, B$ iterations and *carefully* select which $\bt^{(b)}$ are utilized to approximate iid observations from $f(\bt | \bx)$

## Metropolis Algorithm

The Metropolis algorithm restricts $q(\cdot, \cdot)$ to be symmetric so that $q(\bt^{(b)} | \bt^{*}) = q(\bt^{*} | \bt^{(b)})$ and 

$$
A(\bt^{*}, \bt^{(b)}) = \min\left( 1, \frac{L(\bt^{*}; \bx) f(\bt^{*})}{L(\bt^{(b)}; \bx) f(\bt^{(b)})} \right).
$$

## Utilizing MCMC Output

Two common uses of the output from MCMC are as follows:

1.  $\E[f(\bt) | \bx]$ is approximated by 
$$
\hat{\E}[f(\bt) | \bx] = \frac{1}{B} \sum_{b=1}^B f\left(\bt^{(b)}\right).
$$

2.  Some subsequence $\bt^{(b_1)}, \bt^{(b_2)}, \ldots, \bt^{(b_m)}$ from $\left\{\bt^{(b)}\right\}_{b=1}^{B}$ is utilized as an empirical approximation to iid draws from $f(\bt | \bx)$.


## Remarks

- The random draw $\bt^{*} \sim q(\bt | \bt^{(b)})$ perturbs the current value $\bt^{(b)}$ to the next value $\bt^{(b+1)}$.  It is often a Normal distribution for continuous $\bt$.
- Choosing the variance of $q(\bt | \bt^{(b)})$ is important as it requires enough variance for the theory to be applicable within a reasonable number of computations, but it cannot be so large that new values of $\bt^{(b+1)}$ are rarely generated.
- $A(\bt^{*}, \bt^{(b)})$ is called the acceptance probability.
- The algorithm must be run for a certain number of iterations ("burn in") before observed $\bt^{(b)}$ can be utilized.
- The generated $\bt^{(b)}$ are typically "thinned" (only sampled every so often) to reduce Markov dependence.


## Full Conditionals

Suppose that $\bt = (\theta_1, \theta_2, \ldots, \theta_K)$.  Define the subset vector as $\bt_{a:b} = (\theta_a, \theta_{a+1}, \ldots, \theta_{b-1}, \theta_b)$ for any $1 \leq a \leq b \leq K$.  

The full conditional of $\theta_k$ is

$$
\Pr(\theta_k | \bt_{1:k-1}, \bt_{k+1:K}, \bx)
$$

## Gibbs Sampling

Gibbs sampling a special type of Metropolis-Hasting MCMC.  The algorithm samples one coordinate of $\bt$ at a time.

1. Initialize $\bt^{(0)}$.
2. Sample:  
$\theta_1^{(b+1)} \sim \Pr(\theta_1 | \bt_{2:K}^{(b)}, \bx)$  
$\theta_2^{(b+1)} \sim \Pr(\theta_2 | \theta_{1}^{(b+1)}, \bt_{3:K}^{(b)}, \bx)$  
$\theta_3^{(b+1)} \sim \Pr(\theta_3 | \bt_{1:2}^{(b+1)}, \bt_{3:K}^{(b)}, \bx)$  
$\vdots$  
$\theta_K^{(b+1)} \sim \Pr(\theta_K | \bt_{1:K-1}^{(b+1)}, \bx)$  
3. Continue for $b = 1, 2, \ldots, B$ iterations.

## Gibbs and MH

As an exercise, show that Gibbs sampling is a special case of the Metropolis-Hastings algorithm where $A(\bt^{*}, \bt^{(b)}) = 1$.

## Software

[Stan](http://mc-stan.org) is probably the currently most popular software for doing Bayesian computation, including MCMC and variational inference.

There are also popular R packages, such as [`MCMCpack`](https://cran.r-project.org/web/packages/MCMCpack/index.html).

# Extras

## Session Information

<section style="font-size: 0.75em;">
```{r}
sessionInfo()
```
</section>

```{r converttonotes, include=FALSE, cache=FALSE}
source("./customization/make_notes.R")
source("./customization/make_bookdown.R")
```
